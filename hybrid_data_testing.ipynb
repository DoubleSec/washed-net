{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for testing the hybrid tabular + sequential data representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wn import net\n",
    "from wn.data import MatchHistoryDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tensorized data\n",
    "with open(\"data/tensor_list.pkl\", \"rb\") as f:\n",
    "    input_data, y = pickle.load(f)\n",
    "\n",
    "with open(\"data/history_tensor_list.pkl\", \"rb\") as f:\n",
    "    history_data, pid = pickle.load(f)\n",
    "\n",
    "# Load the interfaces\n",
    "with open(\"data/match_interface.pkl\", \"rb\") as f:\n",
    "    match_interface = pickle.load(f)\n",
    "\n",
    "with open(\"data/history_interface.pkl\", \"rb\") as f:\n",
    "    history_interface = pickle.load(f)\n",
    "\n",
    "history_size = 20\n",
    "\n",
    "# Make a dataset\n",
    "ds = MatchHistoryDataset(input_data, y, history_data, pid, history_size=20)\n",
    "\n",
    "# Split into training and validation\n",
    "idx = torch.randperm(len(input_data[\"p1_dob\"]))\n",
    "split_idx = idx.shape[0] // 4  # Just gets a 75/25 split, maximum laziness\n",
    "train_ds = Subset(ds, idx[split_idx:])\n",
    "validation_ds = Subset(ds, idx[:split_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network has 149953 weights.\n",
      "Using cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Set up the network for a test.\n",
    "\n",
    "col_encoding_size = 16\n",
    "dim_model = 64\n",
    "dim_ff = 64\n",
    "n_transformer_layers = 4\n",
    "n_transformer_heads = 4\n",
    "n_output_layers = 3\n",
    "\n",
    "# Special tabular input layer\n",
    "table_input_layer = net.TabularInputLayer(\n",
    "    interface=match_interface,\n",
    "    col_encoding_size=col_encoding_size,\n",
    "    embedding_size=dim_model - col_encoding_size,\n",
    "    append_cls=True,\n",
    ")\n",
    "\n",
    "# Input layer for sequential features\n",
    "sequence_input_layer = net.SequentialInputLayer(\n",
    "    interface=history_interface,\n",
    "    sequence_encoding_size=[history_size, col_encoding_size],\n",
    "    embedding_size=dim_model - col_encoding_size,\n",
    ")\n",
    "\n",
    "output_layers = net.OutputLayers(dim_model, n_output_layers, 1)\n",
    "\n",
    "# Transformer encoder\n",
    "tr = nn.TransformerEncoder(\n",
    "    encoder_layer=nn.TransformerEncoderLayer(\n",
    "        d_model=dim_model,\n",
    "        nhead=n_transformer_heads,\n",
    "        dim_feedforward=dim_ff,\n",
    "        batch_first=True,\n",
    "    ),\n",
    "    num_layers=n_transformer_layers,\n",
    ")\n",
    "\n",
    "whole_net = net.FusionNet(table_input_layer, sequence_input_layer, tr, output_layers)\n",
    "\n",
    "n_weights = sum([p.numel() for p in whole_net.parameters() if p.requires_grad])\n",
    "print(f\"Network has {n_weights} weights.\")\n",
    "\n",
    "# Setup device\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "whole_net.to(device)\n",
    "\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 244 batches of size 1024\n",
      "Validation: 82 batches\n",
      "Starting epoch  1 ------\n",
      "Epoch 1, Batch   50: 0.680 |  Accuracy: 0.56 |    5160 obs/sec |  9.92 s\n",
      "Epoch 1, Batch  100: 0.670 |  Accuracy: 0.58 |    8433 obs/sec |  15.99 s\n",
      "Epoch 1, Batch  150: 0.661 |  Accuracy: 0.59 |    8331 obs/sec |  22.14 s\n",
      "Epoch 1, Batch  200: 0.618 |  Accuracy: 0.62 |    7610 obs/sec |  28.87 s\n",
      "Epoch 1 validation loss: 0.634 |  Accuracy: 0.51 |    5594 obs/sec |  49.10 s\n",
      "Starting epoch  2 ------\n",
      "Epoch 2, Batch   50: 0.582 |  Accuracy: 0.65 |    5375 obs/sec |  58.63 s\n",
      "Epoch 2, Batch  100: 0.553 |  Accuracy: 0.68 |    7325 obs/sec |  65.62 s\n",
      "Epoch 2, Batch  150: 0.538 |  Accuracy: 0.69 |    8054 obs/sec |  71.97 s\n",
      "Epoch 2, Batch  200: 0.526 |  Accuracy: 0.70 |    8394 obs/sec |  78.07 s\n",
      "Epoch 2 validation loss: 0.517 |  Accuracy: 0.70 |    6798 obs/sec |  95.87 s\n",
      "Starting epoch  3 ------\n",
      "Epoch 3, Batch   50: 0.513 |  Accuracy: 0.71 |    5709 obs/sec |  104.84 s\n",
      "Epoch 3, Batch  100: 0.513 |  Accuracy: 0.72 |    7194 obs/sec |  111.95 s\n",
      "Epoch 3, Batch  150: 0.509 |  Accuracy: 0.72 |    7309 obs/sec |  118.96 s\n",
      "Epoch 3, Batch  200: 0.501 |  Accuracy: 0.72 |    7942 obs/sec |  125.41 s\n",
      "Epoch 3 validation loss: 0.499 |  Accuracy: 0.72 |    6578 obs/sec |  143.96 s\n",
      "Starting epoch  4 ------\n",
      "Epoch 4, Batch   50: 0.499 |  Accuracy: 0.72 |    5405 obs/sec |  153.44 s\n",
      "Epoch 4, Batch  100: 0.494 |  Accuracy: 0.73 |    7269 obs/sec |  160.48 s\n",
      "Epoch 4, Batch  150: 0.489 |  Accuracy: 0.73 |    7699 obs/sec |  167.13 s\n",
      "Epoch 4, Batch  200: 0.491 |  Accuracy: 0.73 |    7522 obs/sec |  173.94 s\n",
      "Epoch 4 validation loss: 0.490 |  Accuracy: 0.71 |    7064 obs/sec |  191.25 s\n",
      "Starting epoch  5 ------\n",
      "Epoch 5, Batch   50: 0.489 |  Accuracy: 0.73 |    6090 obs/sec |  199.66 s\n",
      "Epoch 5, Batch  100: 0.487 |  Accuracy: 0.73 |    8131 obs/sec |  205.96 s\n",
      "Epoch 5, Batch  150: 0.488 |  Accuracy: 0.73 |    8051 obs/sec |  212.32 s\n",
      "Epoch 5, Batch  200: 0.487 |  Accuracy: 0.73 |    7803 obs/sec |  218.88 s\n",
      "Epoch 5 validation loss: 0.483 |  Accuracy: 0.73 |    6937 obs/sec |  236.91 s\n",
      "Starting epoch  6 ------\n",
      "Epoch 6, Batch   50: 0.493 |  Accuracy: 0.73 |    6174 obs/sec |  245.20 s\n",
      "Epoch 6, Batch  100: 0.492 |  Accuracy: 0.73 |    8038 obs/sec |  251.57 s\n",
      "Epoch 6, Batch  150: 0.487 |  Accuracy: 0.73 |    8436 obs/sec |  257.64 s\n",
      "Epoch 6, Batch  200: 0.486 |  Accuracy: 0.73 |    8538 obs/sec |  263.64 s\n",
      "Epoch 6 validation loss: 0.484 |  Accuracy: 0.73 |    7045 obs/sec |  280.88 s\n",
      "Starting epoch  7 ------\n",
      "Epoch 7, Batch   50: 0.482 |  Accuracy: 0.73 |    6243 obs/sec |  289.08 s\n",
      "Epoch 7, Batch  100: 0.479 |  Accuracy: 0.73 |    8337 obs/sec |  295.22 s\n",
      "Epoch 7, Batch  150: 0.501 |  Accuracy: 0.72 |    8281 obs/sec |  301.40 s\n",
      "Epoch 7, Batch  200: 0.482 |  Accuracy: 0.73 |    8507 obs/sec |  307.42 s\n",
      "Epoch 7 validation loss: 0.477 |  Accuracy: 0.74 |    7185 obs/sec |  324.57 s\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "# Training parameters. Initially lifted from the simpler network.\n",
    "\n",
    "batch_size = 1024\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Create a dataloader, optimizer, and criterion\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "validation_dl = DataLoader(\n",
    "    validation_ds, batch_size=batch_size, shuffle=True, num_workers=3\n",
    ")\n",
    "\n",
    "print(f\"Training: {len(train_dl)} batches of size {batch_size}\")\n",
    "print(f\"Validation: {len(validation_dl)} batches\")\n",
    "\n",
    "optimizer = AdamW(\n",
    "    filter(lambda p: p.requires_grad, whole_net.parameters()),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "criterion = nn.BCEWithLogitsLoss(reduction=\"sum\")\n",
    "\n",
    "# Per epoch\n",
    "big_tick = perf_counter()\n",
    "\n",
    "# For this amount of data, 5 epochs gives a decent indication of what kind\n",
    "# of performance to expect, it seems.\n",
    "for epoch in range(7):\n",
    "\n",
    "    print(f\"Starting epoch {epoch+1 :2} ------\")\n",
    "\n",
    "    # Training\n",
    "\n",
    "    whole_net.train()\n",
    "\n",
    "    tick = perf_counter()\n",
    "    running_loss = 0.0\n",
    "    running_n = 0\n",
    "    running_correct = 0\n",
    "\n",
    "    for i, batch in enumerate(train_dl):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Get a batch\n",
    "        mx, hx, y, mask = batch\n",
    "\n",
    "        mx = net.to_(mx, device)\n",
    "        hx = net.to_(hx, device)\n",
    "        mask = mask.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        y_hat = whole_net(mx, hx, mask)\n",
    "        labels = y_hat > 0\n",
    "        correct = (labels == y).sum()\n",
    "\n",
    "        loss = criterion(y_hat, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_correct += correct.item()\n",
    "        running_loss += loss.item()\n",
    "        running_n += y_hat.shape[0]\n",
    "\n",
    "        if i % 50 == 49:\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}, Batch {i+1 :4}: {running_loss / running_n :.3f} | \",\n",
    "                f\"Accuracy: {running_correct / running_n :.2f} | \",\n",
    "                f\"{running_n / (perf_counter() - tick) :6.0f} obs/sec | \",\n",
    "                f\"{perf_counter() - big_tick :.2f} s\",\n",
    "            )\n",
    "            running_loss = 0.0\n",
    "            running_n = 0\n",
    "            running_correct = 0\n",
    "            tick = perf_counter()\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    whole_net.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        tick = perf_counter()\n",
    "        valid_loss = 0.0\n",
    "        valid_n = 0\n",
    "        valid_correct = 0\n",
    "\n",
    "        for i, batch in enumerate(validation_dl):\n",
    "\n",
    "            # Get a batch\n",
    "            mx, hx, y, mask = batch\n",
    "\n",
    "            mx = net.to_(mx, device)\n",
    "            hx = net.to_(hx, device)\n",
    "            mask = mask.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_hat = whole_net(mx, hx, mask)\n",
    "            labels = y_hat > 0\n",
    "            correct = (labels == y).sum()\n",
    "\n",
    "            loss = criterion(y_hat, y)\n",
    "\n",
    "            valid_correct += correct.item()\n",
    "            valid_loss += loss.item()\n",
    "            valid_n += y_hat.shape[0]\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1} validation loss: {running_loss / running_n :.3f} | \",\n",
    "            f\"Accuracy: {valid_correct / valid_n :.2f} | \",\n",
    "            f\"{valid_n / (perf_counter() - tick) :6.0f} obs/sec | \",\n",
    "            f\"{perf_counter() - big_tick :.2f} s\",\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tennis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3aaadde310f7da2af25cef5f777dce8f13f327f179bdb50a63ba144a6985ebf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
