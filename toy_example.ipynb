{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wn import net\n",
    "from wn.data import DataInterface, tr\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "x1 = rng.random(100_000)\n",
    "x2 = rng.random(100_000)\n",
    "x3 = rng.random(100_000)\n",
    "\n",
    "# For convenience later\n",
    "all_x = np.stack([x1, x2, x3], axis=1)\n",
    "\n",
    "c1 = rng.integers(0, 2, size=100_000)\n",
    "c2 = rng.integers(0, 2, size=100_000)\n",
    "\n",
    "c_and = c1 * c2\n",
    "\n",
    "# The function here is which max than if c1 or c2 is 0,\n",
    "# and which min if both c1 and c2 are 1\n",
    "y_ = np.zeros_like(x1, dtype=int)\n",
    "y_[c_and == 0] = np.argmax(all_x[c_and == 0, :], axis=1)\n",
    "y_[c_and == 1] = np.argmin(all_x[c_and == 1, :], axis=1)\n",
    "\n",
    "dt = pd.DataFrame(\n",
    "    {\n",
    "        \"x1\": x1,\n",
    "        \"x2\": x2,\n",
    "        \"x3\": x3,\n",
    "        \"c1\": c1,\n",
    "        \"c2\": c2,\n",
    "    }\n",
    ")\n",
    "\n",
    "interface = DataInterface(\n",
    "    {\n",
    "        \"x1\": \"numeric\",\n",
    "        \"x2\": \"numeric\",\n",
    "        \"x3\": \"numeric\",\n",
    "        \"c1\": \"categorical\",\n",
    "        \"c2\": \"categorical\",\n",
    "    }\n",
    ")\n",
    "\n",
    "interface.complete(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDataset(Dataset):\n",
    "    def __init__(self, x, y, interface):\n",
    "\n",
    "        super().__init__()\n",
    "        self.data = {k: tr(x[k], k, interface) for k in interface.type_map}\n",
    "        self.y = y\n",
    "        self.interface = interface\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        x = {k: v[idx, :] for k, v in self.data.items()}\n",
    "        y = self.y[idx, :]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "\n",
    "ds = ToyDataset(dt, torch.tensor(y_, dtype=torch.long).unsqueeze(-1), interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the network for a test.\n",
    "\n",
    "# Special tabular input layer\n",
    "input_layer = net.TabularInputLayer(\n",
    "    interface=interface,\n",
    "    col_encoding_size=8,\n",
    "    embedding_size=24,\n",
    "    append_cls=True,\n",
    ")\n",
    "\n",
    "# Transformer encoder\n",
    "transformer = nn.TransformerEncoder(\n",
    "    encoder_layer=nn.TransformerEncoderLayer(\n",
    "        d_model=32,\n",
    "        nhead=4,\n",
    "        dim_feedforward=32,\n",
    "        batch_first=True,\n",
    "    ),\n",
    "    num_layers=4,\n",
    ")\n",
    "\n",
    "# Ugly convenience layer\n",
    "cls_selector = net.SelectCLSEncoding()\n",
    "\n",
    "# Output layer\n",
    "output_layers = net.OutputLayers(32, 3, 3)\n",
    "\n",
    "whole_net = nn.Sequential(\n",
    "    input_layer,\n",
    "    transformer,\n",
    "    cls_selector,\n",
    "    output_layers,\n",
    ")\n",
    "\n",
    "n_weights = sum([p.numel() for p in whole_net.parameters() if p.requires_grad])\n",
    "print(f\"Network has {n_weights} weights.\")\n",
    "\n",
    "# Setup device\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "whole_net.to(device)\n",
    "\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example training step\n",
    "# Create a dataloader, optimizer, and criterion\n",
    "\n",
    "dl = DataLoader(ds, batch_size=64, shuffle=True)\n",
    "print(f\"{len(dl)} batches\")\n",
    "\n",
    "optimizer = AdamW([p for p in whole_net.parameters() if p.requires_grad])\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "# Per epoch\n",
    "\n",
    "for epoch in range(5):\n",
    "\n",
    "    print(f\"Starting epoch {epoch+1}\")\n",
    "\n",
    "    whole_net.train()\n",
    "\n",
    "    tick = big_tick = perf_counter()\n",
    "    running_loss = 0.0\n",
    "    running_n = 0\n",
    "    running_correct = 0\n",
    "\n",
    "    for i, batch in enumerate(dl):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Get a batch\n",
    "        x, y = batch\n",
    "\n",
    "        x = net.to_(x, device)\n",
    "        y = y.squeeze().to(device)\n",
    "\n",
    "        y_hat = whole_net(x)\n",
    "        labels = torch.max(y_hat, dim=1).indices\n",
    "        correct = (labels == y).sum()\n",
    "\n",
    "        loss = criterion(y_hat, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_correct += correct.item()\n",
    "        running_loss += loss.item()\n",
    "        running_n += y_hat.shape[0]\n",
    "\n",
    "        if i % 50 == 49:\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}, Batch {i+1 :4}: {running_loss / running_n :.3f} | \",\n",
    "                f\"Accuracy: {running_correct / running_n :.2f} | \",\n",
    "                f\"{running_n / (perf_counter() - tick) :6.1f} obs/sec | \",\n",
    "                f\"{perf_counter() - big_tick :.2f} seconds\",\n",
    "            )\n",
    "            running_loss = 0.0\n",
    "            running_n = 0\n",
    "            running_correct = 0\n",
    "            tick = perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This architecture can in fact learn this problem, so it's not totally broken at least."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
