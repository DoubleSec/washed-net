{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wn.data import prepare_matches, DataInterface, tr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we'll construct the pure per-match tabular features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"data/processed_data.pkl\"):\n",
    "\n",
    "    with open(\"data/processed_data.pkl\", \"rb\") as f:\n",
    "        players, matches = pickle.load(f)\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"Loading match list\")\n",
    "    match_list = [f\"../tennis_atp/atp_matches_{year}.csv\" for year in range(1968, 2018)]\n",
    "    matches = prepare_matches(match_list)\n",
    "\n",
    "    print(\"Loading players\")\n",
    "    players = pd.read_csv(\"../tennis_atp/atp_players.csv\")\n",
    "\n",
    "    # Add days elapsed from 1900\n",
    "    print(\"Transforming match dates\")\n",
    "    matches.tourney_date = pd.to_datetime(matches.tourney_date.astype(\"str\"))\n",
    "    matches[\"days_elapsed_date\"] = (\n",
    "        matches.tourney_date - pd.to_datetime(\"19000101\")\n",
    "    ).dt.days\n",
    "\n",
    "    # Removing missing birthday players for now\n",
    "    print(\"Transforming birth dates and removing missing\")\n",
    "    players.dob = pd.to_datetime(players.dob.astype(\"str\"), errors=\"coerce\")\n",
    "    players = players[~players.dob.isna()].reset_index(drop=True)\n",
    "    players[\"days_elapsed_dob\"] = (players.dob - pd.to_datetime(\"19000101\")).dt.days\n",
    "\n",
    "    # Find last match dates\n",
    "    # TKTK: There's a better way to do this\n",
    "    # players[\"last_match_date\"] = [\n",
    "    #     matches[matches.winner_id.eq(r.player_id) | matches.loser_id.eq(r.player_id)].days_elapsed_date.max()\n",
    "    #     for r in players.itertuples()\n",
    "    # ]\n",
    "\n",
    "    # Remove matches with players with unknown birthdays\n",
    "    matches = matches.loc[\n",
    "        matches.winner_id.isin(players.player_id)\n",
    "        & matches.loser_id.isin(players.player_id)\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    # (Hopefully temporarily) remove matches where neither player has\n",
    "    # a known rank\n",
    "    # print(\"Removing missing ranks\")\n",
    "    # matches = matches.loc[\n",
    "    #     ~matches.winner_rank.isna() | ~matches.loser_rank.isna()\n",
    "    # ].reset_index(drop=True)\n",
    "\n",
    "    print(\"Saving processed data\")\n",
    "    with open(\"data/processed_data.pkl\", \"wb\") as f:\n",
    "        pickle.dump((players, matches), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_cols = [\n",
    "    \"winner_rank\",\n",
    "    \"winner_hand\",\n",
    "    \"loser_rank\",\n",
    "    \"loser_hand\",\n",
    "    \"surface\",\n",
    "    \"tourney_level\",\n",
    "    \"days_elapsed_date\",\n",
    "]\n",
    "\n",
    "augmented_matches = (\n",
    "    matches.merge(players, \"inner\", left_on=\"winner_id\", right_on=\"player_id\")\n",
    "    .loc[:, desired_cols + [\"days_elapsed_dob\", \"loser_id\"]]\n",
    "    .rename({\"days_elapsed_dob\": \"winner_dob\"}, axis=1)\n",
    "    .merge(players, \"inner\", left_on=\"loser_id\", right_on=\"player_id\")\n",
    "    .loc[:, desired_cols + [\"winner_dob\", \"days_elapsed_dob\"]]\n",
    "    .rename({\"days_elapsed_dob\": \"loser_dob\"}, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_matches = (\n",
    "    augmented_matches[\n",
    "        [\n",
    "            \"winner_rank\",\n",
    "            \"winner_hand\",\n",
    "            \"winner_dob\",\n",
    "            \"loser_rank\",\n",
    "            \"loser_hand\",\n",
    "            \"loser_dob\",\n",
    "            \"surface\",\n",
    "            \"tourney_level\",\n",
    "            \"days_elapsed_date\",\n",
    "        ]\n",
    "    ]\n",
    "    .fillna(-1)\n",
    "    .assign(won=1)\n",
    "    .rename(\n",
    "        {\n",
    "            \"winner_rank\": \"p1_rank\",\n",
    "            \"winner_hand\": \"p1_hand\",\n",
    "            \"winner_dob\": \"p1_dob\",\n",
    "            \"loser_rank\": \"p2_rank\",\n",
    "            \"loser_hand\": \"p2_hand\",\n",
    "            \"loser_dob\": \"p2_dob\",\n",
    "        },\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "loser_matches = (\n",
    "    augmented_matches[\n",
    "        [\n",
    "            \"loser_rank\",\n",
    "            \"loser_hand\",\n",
    "            \"loser_dob\",\n",
    "            \"winner_rank\",\n",
    "            \"winner_hand\",\n",
    "            \"winner_dob\",\n",
    "            \"surface\",\n",
    "            \"tourney_level\",\n",
    "            \"days_elapsed_date\",\n",
    "        ]\n",
    "    ]\n",
    "    .fillna(-1)\n",
    "    .assign(won=0)\n",
    "    .rename(\n",
    "        {\n",
    "            \"loser_rank\": \"p1_rank\",\n",
    "            \"loser_hand\": \"p1_hand\",\n",
    "            \"loser_dob\": \"p1_dob\",\n",
    "            \"winner_rank\": \"p2_rank\",\n",
    "            \"winner_hand\": \"p2_hand\",\n",
    "            \"winner_dob\": \"p2_dob\",\n",
    "        },\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "condensed_matches = pd.concat([winner_matches, loser_matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_interface = DataInterface(\n",
    "    {\n",
    "        \"p1_rank\": \"numeric\",\n",
    "        \"p1_hand\": \"categorical\",\n",
    "        \"p1_dob\": \"time\",\n",
    "        \"p2_rank\": \"numeric\",\n",
    "        \"p2_hand\": \"categorical\",\n",
    "        \"p2_dob\": \"time\",\n",
    "        \"surface\": \"categorical\",\n",
    "        \"tourney_level\": \"categorical\",\n",
    "        \"days_elapsed_date\": \"time\",\n",
    "    }\n",
    ")\n",
    "\n",
    "match_interface.complete(condensed_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the interface\n",
    "with open(\"data/match_interface.pkl\", \"wb\") as f:\n",
    "    pickle.dump(match_interface, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding p1_rank\n",
      "Encoding p1_hand\n",
      "Encoding p1_dob\n",
      "Encoding p2_rank\n",
      "Encoding p2_hand\n",
      "Encoding p2_dob\n",
      "Encoding surface\n",
      "Encoding tourney_level\n",
      "Encoding days_elapsed_date\n"
     ]
    }
   ],
   "source": [
    "# Now rather expensive to encode, needs to be saved\n",
    "input_data = {\n",
    "    k: tr(condensed_matches[k], k, match_interface) for k in match_interface.type_map\n",
    "}\n",
    "\n",
    "# Also save the labels\n",
    "y = torch.tensor(condensed_matches.won.to_numpy(), dtype=torch.float).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tensor dict and labels\n",
    "with open(\"data/tensor_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump((input_data, y), f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll construct the historical match features.\n",
    "\n",
    "This is all basically identical to the above, except that we need a slightly\n",
    "different look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_cols = [\n",
    "    \"winner_rank\",\n",
    "    \"winner_hand\",\n",
    "    \"loser_rank\",\n",
    "    \"loser_hand\",\n",
    "    \"surface\",\n",
    "    \"tourney_level\",\n",
    "    \"days_elapsed_date\",\n",
    "]\n",
    "\n",
    "augmented_matches = (\n",
    "    matches.merge(players, \"inner\", left_on=\"winner_id\", right_on=\"player_id\")\n",
    "    .loc[:, desired_cols + [\"days_elapsed_dob\", \"loser_id\", \"winner_id\"]]\n",
    "    .rename({\"days_elapsed_dob\": \"winner_dob\"}, axis=1)\n",
    "    .merge(players, \"inner\", left_on=\"loser_id\", right_on=\"player_id\")\n",
    "    .loc[:, desired_cols + [\"winner_dob\", \"days_elapsed_dob\", \"winner_id\", \"loser_id\"]]\n",
    "    .rename({\"days_elapsed_dob\": \"loser_dob\"}, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_matches = (\n",
    "    augmented_matches[\n",
    "        [\n",
    "            \"winner_id\",\n",
    "            \"winner_rank\",\n",
    "            \"loser_rank\",\n",
    "            \"loser_hand\",\n",
    "            \"loser_dob\",\n",
    "            \"surface\",\n",
    "            \"tourney_level\",\n",
    "            \"days_elapsed_date\",\n",
    "        ]\n",
    "    ]\n",
    "    .fillna(-1)\n",
    "    .assign(won=1)\n",
    "    .rename(\n",
    "        {\n",
    "            \"winner_id\": \"p1_id\",\n",
    "            \"winner_rank\": \"p1_rank\",\n",
    "            \"loser_rank\": \"p2_rank\",\n",
    "            \"loser_hand\": \"p2_hand\",\n",
    "            \"loser_dob\": \"p2_dob\",\n",
    "        },\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "loser_matches = (\n",
    "    augmented_matches[\n",
    "        [\n",
    "            \"loser_id\",\n",
    "            \"loser_rank\",\n",
    "            \"winner_rank\",\n",
    "            \"winner_hand\",\n",
    "            \"winner_dob\",\n",
    "            \"surface\",\n",
    "            \"tourney_level\",\n",
    "            \"days_elapsed_date\",\n",
    "        ]\n",
    "    ]\n",
    "    .fillna(-1)\n",
    "    .assign(won=0)\n",
    "    .rename(\n",
    "        {\n",
    "            \"loser_id\": \"p1_id\",\n",
    "            \"loser_rank\": \"p1_rank\",\n",
    "            \"winner_rank\": \"p2_rank\",\n",
    "            \"winner_hand\": \"p2_hand\",\n",
    "            \"winner_dob\": \"p2_dob\",\n",
    "        },\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "# The sort here is super important. It allows us to do relatively optimized\n",
    "# data construction on the fly while training the model, later.\n",
    "\n",
    "condensed_matches = (\n",
    "    pd.concat([winner_matches, loser_matches])\n",
    "    .sort_values([\"p1_id\", \"days_elapsed_date\"])\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding p1_rank\n",
      "Encoding p2_rank\n",
      "Encoding p2_hand\n",
      "Encoding p2_dob\n",
      "Encoding surface\n",
      "Encoding tourney_level\n",
      "Encoding days_elapsed_date\n",
      "Encoding won\n"
     ]
    }
   ],
   "source": [
    "history_interface = DataInterface(\n",
    "    {\n",
    "        \"p1_rank\": \"numeric\",\n",
    "        \"p2_rank\": \"numeric\",\n",
    "        \"p2_hand\": \"categorical\",\n",
    "        \"p2_dob\": \"time\",\n",
    "        \"surface\": \"categorical\",\n",
    "        \"tourney_level\": \"categorical\",\n",
    "        \"days_elapsed_date\": \"time\",\n",
    "        \"won\": \"categorical\",\n",
    "    }\n",
    ")\n",
    "\n",
    "history_interface.complete(condensed_matches)\n",
    "\n",
    "# Encode data to save\n",
    "input_data = {\n",
    "    k: tr(condensed_matches[k], k, history_interface)\n",
    "    for k in history_interface.type_map\n",
    "}\n",
    "\n",
    "# And the player IDs\n",
    "pid = torch.tensor(condensed_matches.p1_id, dtype=torch.int).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save everything\n",
    "\n",
    "with open(\"data/history_tensor_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump((input_data, pid), f)\n",
    "\n",
    "with open(\"data/history_interface.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history_interface, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tennis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3aaadde310f7da2af25cef5f777dce8f13f327f179bdb50a63ba144a6985ebf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
